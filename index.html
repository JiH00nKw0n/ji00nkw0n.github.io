<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jihoon Kwon - Undergraduate Student, AI Researcher</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #494982;
            background: linear-gradient(to bottom, #F4F4FB, #A8A8DB);
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 40px 10px;
        }

        header {
            display: flex;
            align-items: center;
            gap: 40px;
            margin-bottom: 60px;
            border-bottom: 1px solid #828282;
            padding-bottom: 40px;
        }

        .header-left {
            flex: 1;
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
        }

        .header-right {
            flex: 3;
            text-align: left;
            padding-left: 10px;
        }

        .profile-img {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            margin-bottom: 20px;
            border: 3px solid #f0f0f0;
            object-fit: cover;
        }

        h1 {
            font-size: 2.5em;
            font-weight: 700;
            margin-bottom: 10px;
            color: #5E5E82;
        }

        .title {
            font-size: 1.3em;
            color: #696982;
            margin-bottom: 20px;
        }

        .contact-info {
            display: flex;
            justify-content: center;
            gap: 20px;
            flex-wrap: wrap;
            margin-bottom: 20px;
        }

        .contact-info a {
            color: #737382;
            text-decoration: none;
            font-size: 1.5em;
            transition: transform 0.2s ease;
        }

        .contact-info a:hover {
            transform: scale(1.2);
        }

        .iico {
            width: 24px;
            height: 24px;
            filter: invert(44%) sepia(9%) saturate(634%) hue-rotate(215deg) brightness(95%) contrast(85%);
        }

        .bio {
            max-width: 800px;
            margin: 0;
            text-align: left;
            color: #545482;
            line-height: 1.4;
        }

        .bio p {
            margin-bottom: 15px;
        }

        .bio p:last-child {
            margin-bottom: 0;
        }

        section {
            margin-bottom: 50px;
        }

        section em {
            color: #000000;
            font-style: italic;
            text-decoration: underline;
        }

        h2 {
            font-size: 1.8em;
            font-weight: 600;
            margin-bottom: 25px;
            color: #494982;
            border-bottom: 2px solid #7D7D82;
            padding-bottom: 5px;
        }

        .publication-item {
            margin-bottom: 25px;
            padding: 20px;
            background-color: rgba(255, 255, 255, 0.3);
            border-left: 4px solid #7D7D82;
            border-radius: 0 5px 5px 0;
        }

        .publication-title {
            font-weight: 600;
            font-size: 1.1em;
            color: #494982;
            margin-bottom: 8px;
        }

        .publication-authors {
            font-style: italic;
            color: #696982;
            margin-bottom: 5px;
        }

        .publication-venue {
            color: #737382;
            font-weight: 500;
            margin-bottom: 8px;
        }

        .publication-links {
            margin-top: 10px;
        }

        .publication-links a {
            display: inline-block;
            padding: 4px 12px;
            background-color: #7D7D82;
            color: white;
            text-decoration: none;
            border-radius: 3px;
            font-size: 0.85em;
            margin-right: 8px;
            margin-bottom: 5px;
        }

        .publication-links a:hover {
            background-color: #696982;
        }

        .education-item, .experience-item, .project-item {
            margin-bottom: 25px;
            padding-bottom: 20px;
            border-bottom: 1px solid #828282;
            position: relative;
            padding-left: 70px;
        }

        .education-item, .experience-item, .project-item {
            padding-left: 90px;
        }

        .company-logo {
            position: absolute;
            left: 0;
            top: 0;
            width: 70px;
            height: 70px;
            object-fit: contain;
        }

        .project-logo {
            position: absolute;
            left: 0;
            top: 0;
            width: 70px;
            height: 70px;
            object-fit: contain;
        }

        .school-logo {
            position: absolute;
            left: 0;
            top: 0;
            width: 70px;
            height: 70px;
            object-fit: contain;
        }

        .education-item:last-child, .experience-item:last-child, .project-item:last-child {
            border-bottom: none;
        }

        .item-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 10px;
            flex-wrap: wrap;
        }

        .item-title {
            font-weight: 600;
            color: #494982;
            font-size: 1.1em;
        }

        .item-institution, .item-company {
            color: #737382;
            font-weight: 500;
        }

        .item-date {
            color: #696982;
            font-size: 0.9em;
            white-space: nowrap;
        }

        .item-description {
            margin-top: 10px;
            color: #5E5E82;
        }

        .item-description ul {
            padding-left: 20px;
            margin-top: 8px;
        }

        .item-description li {
            margin-bottom: 5px;
        }

        .project-tech {
            margin-top: 10px;
        }

        .tech-tag {
            display: inline-block;
            background-color: #7D7D82;
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 0.85em;
            margin-right: 6px;
            margin-bottom: 4px;
        }

        .blog-item {
            margin-bottom: 20px;
            padding: 15px 0;
            border-bottom: 1px solid #828282;
        }

        .blog-item:last-child {
            border-bottom: none;
        }

        .blog-title {
            font-weight: 600;
            color: #494982;
            text-decoration: none;
            font-size: 1.1em;
        }

        .blog-title:hover {
            color: #737382;
        }

        .blog-date {
            color: #696982;
            font-size: 0.9em;
            margin-top: 5px;
        }

        .blog-excerpt {
            margin-top: 8px;
            color: #5E5E82;
        }

        footer {
            text-align: center;
            margin-top: 60px;
            padding-top: 30px;
            border-top: 1px solid #828282;
            color: #696982;
            font-size: 0.9em;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px 10px;
            }

            header {
                flex-direction: column;
                gap: 30px;
                text-align: center;
            }

            .header-left, .header-right {
                flex: none;
            }

            .header-right {
                text-align: center;
            }

            h1 {
                font-size: 2em;
            }

            .contact-info {
                justify-content: center;
                gap: 15px;
            }

            .item-header {
                flex-direction: column;
                align-items: flex-start;
            }

            .item-date {
                margin-top: 5px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <div class="header-left">
                <h1>Jihoon Kwon</h1>
                <img src="assets/profile.jpeg" alt="Jihoon Kwon" class="profile-img">
                <div class="contact-info">
                    <a href="mailto:kog0712@snu.ac.kr">
                        <img src="assets/mail.svg" class="iico" alt="Connect with Jihoon via Email">
                    </a>
                    <a href="https://github.com/JiH00nKw0n">
                        <img src="assets/github.svg" class="iico" alt="Connect with Jihoon on GitHub">
                    </a>
                    <a href="https://www.linkedin.com/in/jihoonkwon-127312240">
                        <img src="assets/linkedin.svg" class="iico" alt="Connect with Jihoon on LinkedIn">
                    </a>
                    <a href="https://scholar.google.com/citations?user=AFBlcwsAAAAJ&hl=ko">
                        <img src="assets/googlescholar.svg" class="iico" alt="Connect with Jihoon on Google Scholar">
                   </a>
                </div>
            </div>
            <div class="header-right">
                <div class="title">Extraordinary achievements are born from the accumulation of ordinary efforts.</div>
                <div class="bio">
                    <p>
                      My research focuses on two complementary capabilities that together enable <em>multimodal understanding</em> and <em>contextual adaptability</em>:
                      aligning vision and language representations and enabling context-driven reasoning.
                    </p>

                    <p>
                      On the training side, I research methods for better <strong>vision‚Äìlanguage alignment</strong> so that models can perceive and describe the world more like humans.
                      On the inference side, I study how large language models perform <strong>in-context learning</strong> to adapt to novel information on the fly.
                      Ultimately, my goal is to advance AI systems that can understand and adapt to the world as humans do.
                    </p>
                </div>
            </div>
        </header>
        <section id="interests">
            <h2>Research Interest</h2>
            <p>
                My research interests stem from a fundamental observation: despite the remarkable progress in foundation models, these models <em>still struggle with tasks that humans perform in a fundamental and intuitive manner</em> - revealing critical gaps in how machines understand and reason about the world.
                I firmly believe that developing models capable of understanding and reasoning in a human-like way is essential to advancing human freedom, equality, and social solidarity.
            </p>
        </section>

        <section id="publications">
            <h2>Publications</h2>
            
            <div class="publication-item">
                <div class="publication-title">Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions</div>
                <div class="publication-authors"><strong>Jihoon Kwon</strong>, Kyle Min, Jy-yong Sohn</div>
                <div class="publication-venue">The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS 2025 Poster)</div>
                <div class="publication-links">
                    <a href="https://neurips.cc/virtual/2025/poster/119758">Paper</a>
                    <a href="https://anonymous.4open.science/r/READ-CLIP-6311/README.md">Code</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Thematic Scoring: Quantifying Contextual Narratives using Language Models</div>
                <div class="publication-authors">Alejandro Lopez-Lira, Chanyeol Choi, Yoon Kim, <strong>Jihoon Kwon</strong>, Jin Kim, Suyeol Yun</div>
                <div class="publication-venue">SSRN 5233994</div>
                <div class="publication-links">
                    <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5233994">Paper</a>
                </div>
            </div>

            <div class="publication-item">
                <div class="publication-title">Linq-Embed-Mistral Technical Report</div>
                <div class="publication-authors">Chanyeol Choi, Junseong Kim, Seolhwa Lee, <strong>Jihoon Kwon</strong>, Sangmo Gu, Yejin Kim, Minkyung Cho, Jy-yong Sohn</div>
                <div class="publication-venue">ArXiv 2412.03223</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2412.03223">Paper</a>
                    <a href="https://huggingface.co/Linq-AI-Research/Linq-Embed-Mistral">Model</a>
                </div>
            </div>
        </section>

        <section id="education">
            <h2>Education</h2>

            <div class="education-item">
                <img src="assets/snu.svg" alt="Seoul National University" class="school-logo">
                <div class="item-header">
                    <div>
                        <div class="item-title">B.S. in Industrial Engineering</div>
                        <div class="item-institution">Seoul National University, Republic of Korea</div>
                    </div>
                    <div class="item-date">2019/02 - 2025/08</div>
                </div>
                <div class="item-description">
                    Double Major: Business Administration<br>
                    Relevant Coursework: Machine Learning, Optimization, Statistics
                </div>
            </div>
        </section>

        <section id="experience">
            <h2>Work Experience</h2>
            
            <div class="experience-item">
                <img src="assets/linqalpha.svg" alt="LinqAlpha" class="company-logo">
                <div class="item-header">
                    <div>
                        <div class="item-title">Fundamental Research Engineer - AI/LLM</div>
                        <div class="item-company">LinqAlpha</div>
                    </div>
                    <div class="item-date">2023/09 - Present</div>
                </div>
                <div class="item-description">
                    <ul>
                        <li>Developing a GUI-based Vision-Language-Action agent to automatically enter, record, and transcribe earnings, conference, and special calls.</li>
                        <li>Taking full ownership of research and critical experiments applying LLMs in finance.</li>
                        <li>Building and managing an end-to-end project to develop, collect and publish a finance-specific benchmark for training and evaluating LLMs.</li>
                    </ul>
                </div>
            </div>

        </section>

        <section id="projects">
            <h2>Projects</h2>

            <div class="project-item">
                <img src="assets/sqa.avif" alt="SQA Alphathon 2025" class="project-logo">
                <div class="item-header">
                    <div class="item-title">üèÜ SQA Alphathon 2025 Winner (Can LLMs Hit Moving Targets? Tracking Evolving Signals in Corporate Disclosures)</div>
                    <div class="item-date">Oct 2025</div>
                </div>
                <div class="item-description">
                    Led and developed an end-to-end system that predicts stock returns by detecting when companies strategically shift the metrics they emphasize in earnings calls:
                    <ul>
                        <li><strong>Project Leadership:</strong> Took full ownership from problem formulation to implementation, developing novel extraction and scoring methods that achieved significantly stronger predictive performance for stock return forecasting</li>
                        <li><strong>Novel Extraction & Scoring:</strong> Developed LLM-based extraction method to identify performance metrics with full context, and designed semantic scoring system to measure how metrics shift over time‚Äîaddressing limitations of traditional keyword-based approaches that lose contextual information</li>
                        <li><strong>Stronger Predictions:</strong> Achieved 3.6√ó better stock return forecasting compared to the original method, demonstrating how LLMs can improve investment signal detection in real markets</li>
                    </ul>
                </div>
                <div class="publication-links">
                    <a href="https://www.alphathon.org/winners/">Competition</a>
                    <a href="https://www.linkedin.com/posts/society-of-quantitative-analysts_csp-alphathon-alphathon2025-activity-7382497413611134976-JSV6?utm_source=share&utm_medium=member_desktop&rcm=ACoAADvYwy8B2B-Te9RxithhN1mpwqEiCljaC_4">LinkedIn</a>
                    <a href="https://arxiv.org/abs/2510.03195">Paper</a>
                </div>
            </div>

            <div class="project-item">
                <img src="https://framerusercontent.com/images/hR0zBf3gaEChVdowK2MBsfMrwHc.png?scale-down-to=2048&lossless=1" alt="LinqAlpha Project" class="project-logo">
                <div class="item-header">
                    <div class="item-title">üèÜ World Best Vector-based Retrieval Model (Linq-Embed-Mistral)</div>
                    <div class="item-date">May 2024</div>
                </div>
                <div class="item-description">
                    Contributed significantly to developing Linq-Embed-Mistral, achieving #1 ranking on the MTEB leaderboard (as of March 2025):
                    <ul>
                        <li><strong>MTEB #1 Achievement:</strong> Developed model that ranked #1 on Hugging Face MTEB leaderboard among 200+ models, surpassing OpenAI, Google, Cohere, and Nvidia in retrieval accuracy</li>
                        <li><strong>Data Pipeline Engineering:</strong> Built end-to-end data curation pipeline including dataset selection, filtering, and hard negative mining strategies that were critical to achieving top benchmark performance</li>
                        <li><strong>Training & Optimization:</strong> Designed and executed training experiments that achieved state-of-the-art results with 95% zero-shot evaluation score, demonstrating strong generalization without benchmark overfitting</li>
                    </ul>
                </div>
                <div class="publication-links">
                    <a href="https://huggingface.co/spaces/mteb/leaderboard">Leaderboard</a>
                    <a href="https://www.linkedin.com/posts/chanyeolchoi_weve-just-updated-the-mteb-embeddings-activity-7300563744697290752-bVjV?utm_source=share&utm_medium=member_desktop&rcm=ACoAADvYwy8B2B-Te9RxithhN1mpwqEiCljaC_4">LinkedIn</a>
                    <a href="https://linqalpha.com/blog/linq-embed-mistral">Blog</a>
                </div>
            </div>
        </section>

        <section id="blog">
            <h2>Blog</h2>
<!--            -->
<!--            <div class="blog-item">-->
<!--                <a href="#" class="blog-title">The Future of Large Language Models: Scaling and Efficiency</a>-->
<!--                <div class="blog-date">March 15, 2024</div>-->
<!--                <div class="blog-excerpt">-->
<!--                    Exploring the latest developments in LLM architectures and discussing the trade-offs between -->
<!--                    model size, computational efficiency, and performance across different tasks.-->
<!--                </div>-->
<!--            </div>-->

        </section>

        <footer>
            <p>&copy; 2025 Jihoon Kwon. All rights reserved.</p>
        </footer>
    </div>
</body>
</html>